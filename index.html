<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Introducción al PLN, un enfoque clínico</title>

		<meta name="description" content="Unidad Técnica Snomed-CT España. Intro PLN Clinico">
		<meta name="author" content="Ignacio Martinez Soriano">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">

		<link rel="stylesheet" href="css/theme/beige.css" id="theme"> 
	
		<!-- <link rel="stylesheet" href="css/main.css"> 
			 <link rel="stylesheet" href="css/theme/league.css" id="theme"> -->
		
		
		<!-- For syntax highlighting  -->
        <link rel="stylesheet" href="lib/css/zenburn.css">
		
		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
			
			<section data-background-transition="slide" data-background="images/Lorca01.jpg" style="background: rgba(0,129,195,.9); color: white" >
				<h4 style="color: rgba(255, 225, 255, .9)">
					"Introducción al Procesamiento Lenguaje Natural, un enfoque clínico."<br>
				</h4>
				<h3 style="color: rgba(255, 225, 255, .9)">
					Introducción al PLN Clínico. Evolución de la I.A.
				</h3>
				
				<p>Ignacio Martinez Soriano</p>
				
				<h4 style="color: rgba(255, 225, 255, .9)">
					15-Oct-2021 (Lorca) Webminar
					<img src="images/QR-PLNClinical.png" style="float: right; border: 0; padding: 0px; width: 20%; height: 20%"></img>

				</h4>

				<small><p>Unidad Técnica Snomed-CT<br>
						Hospital Universitario "Rafael Mendez"<br>
				</p></small>

			</section>
				<section>
					<h1>PLN-Clinical</h1>
					<ul>
						<li>Introduction IA y PLN</li>
						<li>Ciclo de Vida Sistema M.L.</li>
						<li>Sistemas Tradiciones PLN</li>
						<li>Word Embedding</li>
						<li>Snomed2Vec Approach</li>
						<li>Transformers</li>
						<li>Casos de Uso y Librerias</li>
						<li>Conclusiones y Propuestas</li>
					</ul>
				</section>
				<section>
					<section data-transition="zoom" data-background="images/cbms_fondo00.jpg">
						<h2 style="display:block;background:rgba(235,235,235,0.7);color:#404040;padding:13px 10px 10px 10px;border-radius:3px;">1. Introduction:</h2>
					</section>												

					<section>
						<h2>Introduction:</h2>
						<p><strong>¿De dónde partimos?</strong></p>
						<table>
							<tr>
							    <td>En Agosto de 1955 el profesor de Matemáticas, <strong>John McCarthy</strong>, organiza una Conferencia en la Universidad de Dartmouth, donde se define el concepto de Inteligencia Artificial,
							denotándola como  un proceso por el que "una máquina se puede comportar de formas que serían llamadas inteligentes si un ser humano hiciera eso"
							    </td>
							     <td>
							       <img src="images/McCarthy.jpg" > </img>
							     </td>
							</tr>
						</table>
						<hr>
						
						<p>En Agosto de 1955 el profesor de Matemáticas, <strong>John McCarthy</strong>, organiza una Conferencia en la Universidad de Dartmouth, donde se define el concepto de Inteligencia Artificial,
							denotándola como  un proceso por el que "una máquina se puede comportar de formas que serían llamadas inteligentes si un ser humano hiciera eso" </p>
						<img src="images/McCarthy.jpg" style="border: 0; padding: 0px; width: 50%; height: 50%"> </img>

					</section>
					<section>
						<h3>I.A., Machine Learning y PLN:</h3>
						<small><p>To identify the diagnosis and procedure, from the free text, we need a Clinical Terminology (ICD-10-MC,Snomed-CT..)</p></small>
						<img src="images/McCarthy.jpg" style="border: 0; padding: 0px; width: 70%; height: 70%"> </img>
						<p>This process is heavy and need an expert.</p>

					</section>		
					<section>
						<h3>Mapping Clinical Concept:</h3>
						<small><p>To identify the diagnosis and procedure, from the free text, we need a Clinical Terminology (ICD-10-MC,Snomed-CT..)</p></small>
						<img src="images/codification.png" style="border: 0; padding: 0px; width: 70%; height: 70%"> </img>
						<p>This process is heavy and need an expert.</p>

					</section>
					<section>
						<h2>Spanish NER Tool approach:</h2>
						<p>We propossed a tool to help the clinicians, to search in Snomed-CT and find the correct Medical concept Code.</p>
						<p><strong><em>Snomed2Vec</em></strong>, is an ontology based named entity recognition tool using word embedding, that
							suggest what is the most similar concept of Snomed-CT, that appear in a text.</p>
						<p><strong>Snomed2Vec</strong>, from a query text, It suggest what is
								the most similar concepts from Snomed-CT grouping by its top level hierarchy.</p>
					</section>
					<section>
						<h3>Background and Related Work:</h3>
						<p>Different approach of Ontology-Based Names Entity recognition.</p>
						<ul>
							<li>Ontology Matching.</li>
							<small><p>Try to solve a problem of semantic heterogeneity</p></small>
							<li>Named Based Techniques.</li>
							<small><p>Try to identify the most similar string in a text search</p></small>
							<li>Word Embedding Ontology Matching.</li>
							<small><p>Represent entities in ontologies with word embedding</p></small>
						</ul>
						<p></p>
					</section>
				</section>
				
				<section>
					<section data-transition="zoom"; data-background="images/cbms_fondo01.jpg">
						<h2 style="display:block;background:rgba(235,235,235,0.7);color:#404040;padding:13px 10px 10px 10px;border-radius:3px;">2. Word embedding:</h2>
					</section>
					<section>
						<h2>Initial Idea: </h2>
						<img src="images/DonQuijote.jpg" style="float: left; border: 0; padding: 0px; width: 40%; height: 40%"></img>
						In Spanish there is a proverb:
						<blockquote class="fragment fade-up" cite="https://cvc.cervantes.es/lengua/refranero/ficha.aspx?Par=58521&Lng=0">
							&ldquo;Dime con quien andas y te diré quien eres&rdquo;
						</blockquote>
						<small>[El Quijote II, 10 y 23]</small>
						<blockquote class="fragment fade-up" cite="https://cvc.cervantes.es/lengua/refranero/ficha.aspx?Par=58521&Lng=0">
							&ldquo;Tell me who you are your frinds and I'll tell you, who you are&rdquo;
						</blockquote>
					</section>
					<section>

						<pre><code data-trim style="text-align: center;">To identify the semantic meaning of a word, 
it depend of the words around it.</code></pre>

						<p><strong>Word Embedding</strong> are based on the idea that contextual information alone 
							constitutes a viable representation of linguistic terms</p>
						<p>In <em>computational linguistic</em>, we use the term <strong>distributional semantic model</strong>, 
							<em>linguistic items with similar distributions have similar meanings.</em> </p>
					</section>
					<section>
						<h3>Evolution:</h3>
						<ul>
							<li>In 2003 <strong>Bengio et al.</strong> proposed a Neural language Model which learned distributed representations for words</li>
							<li class="fragment fade-up"><strong>Collobert and Westorn</strong>(2008) was the firts work to show the utility of pre-trained word embeddings</li>
							<li class="fragment fade-up">In 2013 <strong>Mikolov et al.</strong> proposed <em>Word2Vec</em>, with two approach, 
								<em>continous bag-of-word</em> and <em>skip-gram</em>, to construct high quality distributed vector representations</li>
						</ul>
					</section>
					<section>
						<h1>what is Word2Vec? </h1>
					</section>
					<section>
						<strong><em>Word2Vec</em></strong> is a shallow neural networks with one hidden layer, to produce word embedding
						<img src="images/W2V-Architecture.png" style="border: 0; padding: 0px; width: 60%; height: 60%"> </img>	

						<small>				
							<ol>
								<li>Input is a <strong>One hot</strong> vector of all words from text</li>
								<li>One hide layer, with <strong>size</strong> of the word vector </li>
								<li>A output layer, using a <strong>SoftMax</strong> classifier</li>
							</ol>
						</small>
	
					</section>
					<section>
						<p>Word2vec is two approach– CBOW(Continuous bag of words) and Skip-gram model.</p>
						<p><small>Learn weights which act as word vector representations, with a <strong>size window</strong>, about the word context</small></p>
						<img src="images/CBOW-SkipGram.png" style="border: 0; padding: 0px; width: 50%; height: 50%"> </img>
						<p style="font-size: 20px">The training method of word2vec is backpropagation with stochastic gradient descent.</p>
						<img src="images/CBOW-ObjectiveFunc.png" style="float: left; border: 0; padding: 0px; width: 40%; height: 40%"> </img>
						<img src="images/SkipGram-ObjectiveFunc.png" style="float: right;border: 0; padding: 0px; width: 40%; height: 40%"> </img>
					</section>
					<section>
						<p><strong>Word2Vecs'trick:</strong></p>

						<p>There is no activation function on the hidden layer neurons, and the output neurons use softmax clasification 
							method to build a probability distribution.</p>
						
						<p>Really, the goal is just to learn the weights of the hidden layer. 
								It'll be the “word vectors”.</p>
						<blockquote>The hidden layer, represent the vector of the word in the space model</blockquote>
					</section>
				</section>
				
				<section>
					<section data-transition="zoom" data-background="images/cbms_fondo03.jpg">
						<h2 style="display:block;background:rgba(235,235,235,0.7);color:#404040;padding:13px 10px 10px 10px;border-radius:3px;">3. Snomed-CT:</h2>
					</section>
					<section>
						<h2>Snomed-CT</h2>
						<p><small>Systematized Nomenclature of Medicine Clinical Terms</small></p>
						<p><strong>Component</strong>, is organized in concepts, descriptions and relationships: </p>
						<ul>
								<li class="fragment fade-up"><strong>Concepts</strong>, is the way to represent a clinical concept.</li>
								<li class="fragment fade-up"><strong>Descriptions</strong>, represeting the human readable term of a concept</li>
								<li class="fragment fade-up"><strong>Relationships</strong>, represent an association between concepts.</li>
						</ul>
						<small><p>The meaning of the concept has a hierarchy structure, from general to more detail.</p></small>
					</section>
					<section>
							<h3>Logic Model (1/2)</h3>
							<img src="images/Snomed-logicalModel.png" style="border: 0; padding: 0px;"> </img>
							<p style="font-size: 15px">Figure01: <a href="https://confluence.ihtsdotools.org/display/DOCSTART/5.+SNOMED+CT+Logical+Model"">ihtsdo web</a></p>
					</section>
					<section>
						<h3>Logic Model (2/2)</h3>
						<img src="images/Snomed-Structure.png" style="border: 0; padding: 0px;"> </img>
						<p style="font-size: 15px">Figure02: <a href="https://confluence.ihtsdotools.org/display/DOCSTART/5.+SNOMED+CT+Logical+Model"">ihtsdo web</a></p>
					</section>					
				</section>

				<section>
					<section data-transition="zoom" data-background="images/cbms_fondo04.jpg">
						<h2 style="display:block;background:rgba(235,235,235,0.7);color:#404040;padding:13px 10px 10px 10px;border-radius:3px;">4. Snomed2Vec Approach:</h2>
					</section>	
					<section>
						<h3>1. DataSets Creations:</h3>
							<img src="images/Snomed2Vec-DataSets.png" style="border: 0; padding: 0px; width: 40%; height: 40%"> </img>
					</section>
					<section>
						<h3>2. Pre-processing Text:</h3>
						<small>
						<ol>
								Initial DataSets for training:<br><br>
							<li><strong>DataSet_Model01</strong>: local domain.(Discharge Emergency Reports + Snomed-cT Descriptions)</li>
							<ul>
								<li>516.211 discharge emergency reports from (2009-2018)</li>
								<li>636.439 Snomed-CT descriptions Terms</li> 
								<li>Final size of DataSetModel01 to train, 1.152.650</li>
							</ul>
							<li><strong>DataSet_Model02</strong>, (Spanish Wikipedia Dump + Snomed-cT Descriptions), General domain</li>
							<ul>
								<li><a href="https://github.com/attardi/wikiextractor">Link to: WikiExtractor framework</a> from Guiseppe Attardi</li>
							</ul>

							<li><strong>Normalized Text:</strong></li>
								<ul>
									<li>Tokenizer the text</li>
									<li>Lowing words, removing some punctuation sign.</li>
									<li>Eliminating Spanish accent</li>
									<li>Remove some <strong>StopWord</strong>, but not the negative words</li>
								</ul>
						</ol>
						</small>
					</section>
					<section>
						<h3>3. Apply Word2Vec Gensim (Skipgram) framework</h3>
						<ul>
							<strong>Parameters:</strong>
							<li>Size=300, size of the vector</li>
							<li>Window=8, Context size</li>
							<li>min_count=1, less frecuency word</li>
							<li>sh=1, SkipGram framework</li>
							<li>hs= SoftMax, classifier</li>
						</ul>
						<p>After trainning process, we get 2 model.</p>
					</section>
					<section>
						<h3>4. Final Words Space Vector Models</h3>
						<ol>
							<li><strong>Model_01</strong>, local domain trainning model, (Emergency Reports + Snomed Descriptions)</li>
							<li><strong>Model_02</strong>, General domain trainning model, (Spanish Wikipedia + Snomed Descriptions)</li>
						</ol>
						<p>With theses models we get the vector of every word</p>
					</section>
				</section>

				<section>
					<section data-transition="zoom" data-background="images/cbms_fondo05.jpg">
						<h2 style="display:block;background:rgba(235,235,235,0.7);color:#404040;padding:13px 10px 10px 10px;border-radius:3px;">5. Final Snomed2Vec Model And Similarity Methods:</h2>
					</section>	
					<section>
						<h2>1. Final Snomed2Vec Model.</h2>
						<p>To get the final Snomed2Vec model approach, we use the previous Models (01, 02), to create a 2 news space Model, 
							with the descripcions tems of Snomed-CT.</p>
						<p>From the Snomed-CT DataSet, with the structure:</p>
						<img src="images/Snomed2Vec-DataSet00.png" style="border: 0; padding: 0px; width: 40%; height: 40%"> </img>
						<small>
							<p>(*)Link to: get the Top level hierarchy of a concept, we need to use: <a href="https://confluence.ihtsdotools.org/display/DOCTSG/7.5.2+Transitive+closure+implementation">Snomed-CT Transitive closure implementation</a></p>
						</small>
					</section>
					<section>
						<h2>2. Getting final description Vector</h2>
						<p>Use the previous Word Space Models, to get the final description terms vector.</p>
						<ol>
							<li>Description Terms => <em><strong>(d)</strong></em> = (w<sub>1</sub> + w<sub>2</sub> + ... + w<sub>n</sub>)</li>
							<li><em><strong>v(d)=</strong></em> &sum;<sub>(i=1)</sub> v[w<sub>i</sub>] &equiv; v[w<sub>1</sub>]+v[w<sub>2</sub>]+...+v[w<sub>n</sub>]
							</li>
						</ol>
					</section>
					<section>
						<h2>3. Final Space Model - Snomed2Vec</h2>
						<p>New Vector Space Model, <strong>Snomed2Vec</strong></p>
						<img src="images/SnomedWork.png" style="border: 0; padding: 0px; width: 90%; height: 90%"> </img>
						<small>
							<p>Size of the Space Vector Model: (516211, 4)</p>
							<p>[ID_Concept] [corpusTerm] [Hierarchy] [Vector(Description)]</p>
						</small>
					</section>
					<section>
						<h2>3.1 Design Process - Snomed2Vec</h2>
						<img src="images/Snomed2Vec-Process01.png" style="border: 0; padding: 0px; width: 60%; height: 60%"> </img>
						<hr>
						<img src="images/Snomed2Vec-Process02.png" style="border: 0; padding: 0px; width: 60%; height: 60%"> </img>
					</section>
					<section>
						<h2>4. Similarity Distance - New Approach</h2>
						<p>We use the Cosine distance, to identify the similarity between concepts</p>
						<img src="images/cosine-similarity.png" style="border: 0; padding: 0px; width: 50%; height: 50%"> </img>
						<p>Our approach is:</p>
						<small>
						<ul>
							<li>we use <strong>Gensim distance</strong> of the Similarity method implementation, but not, over the the Space model of the trainner model (01, 02).</li>
							<li>We apply over the <strong>Final Snomed2Vec</strong> space Model.</li>
						</ul>
						</small>
					</section>
					<section>
						<h2>4.1 Space Vector Model Snomed2Vec</h2>
						<small>
						<table>
								<thead><tr>
									<th>Number</th>	
									<th>Id-Concept</th>
									<th>Vector(description Term)</th>
								</tr></thead>
								<tbody>
									<tr>
										<td>0.</td>
										<td>102002</td>
										<td>[0.503108, 0.466876, -0.0276602, -0.234006, -0.116602, 0.484161, 0.125, -0.351791, 0.168337, -0...</td>
									</tr>
									<tr>
										<td>1</td>
										<td>103007</td>
										<td>[[1.08219, -0.860717, 0.460997, 0.467138, -0.109274, 0.35905, 0.0495269, -1.52099, 0.485955, -0....</td>
									</tr>
									<tr>
										<td>...</td><td>...</td><td>...</td>							
									</tr>
									<tr>
										<td>...</td><td>...</td><td>...</td>							
									</tr>
									<tr>
										<td>516211</td>
										<td>...</td>
										<td>[[1.09046, 1.19666, 0.137113, 1.16608, -1.54469, 1.88294, 0.745489, -1.53078, 0.679535,...</td>							
									</tr>
		
								</tbody>
							</table>
						</small>
					</section>
					<section>
						<h2>Implementation tricks 1/2</h2>
						<small>
						<p><a href="https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/word2vec.py">Link to: Gensim implementation</a>, to our solution</p>
						<p>Creation of the Initial Matrix to get the Snomed2Vec Vector Space Model</p>
						</small>
						<pre><code class="python" data-trim contenteditable style="font-size: 15px;">
# Input data = DataSet-Matrix
def init_vars(data):
    vector_size = len(data['vecSnom'][0])
    vocab_size = len(data['vecSnom'])
    logging.info("precomputing L2-norms of word weight vectors")
    index2word = data['concept'].tolist() # map from a word's matrix index (int) to word (string)
    syn0 = np.array(data['vecSnom'].tolist(), dtype=REAL)
    syn0[np.isnan(syn0)] = 0.0
    syn0norm = zeros((vocab_size, vector_size), dtype=REAL)
    np.seterr(divide='ignore', invalid='ignore')
    syn0norm = (syn0 / sqrt((syn0 ** 2).sum(-1))[..., newaxis]).astype(REAL)
    return syn0, index2word, syn0norm
						</code></pre>
					</section>					
					<section>
						<h2>Implementation tricks 2/2</h2>
						<pre><code class="python" data-trim contenteditable style="font-size: 15px;">
	def mas_similar(positive=[], model=w2vModel, topn=15):
    	vector=vectorSnomed(positive,model,300)
    	vectorNorm = (vector / sqrt((vector ** 2).sum(-1))[..., newaxis]).astype(REAL)
    	mean = []
    	mean.append(vectorNorm)
    	mean = matutils.unitvec(array(mean).mean(axis=0)).astype(REAL)
    	limited = syn0norm
    	dists = dot(limited, mean)
    	dists[np.isnan(dists)] = 0.0
    	best = matutils.argsort(dists, topn=topn, reverse=True)
    	result = [(index2word[sim], float(dists[sim])) for sim in best]
    	return result[:topn]
						</code></pre>
					</section>
					<section>
						<h2>5. New Methods Snomed2Vec</h2>
						<p>We create next methods to use with Snomed2Vec:</p>
						<small>
						<ol>
							<li><strong>vectorSnomed</strong>(queryText, model, size):</li>
							<ul><li> Out: q(Query txt), v(q)= &sum;<sub>(i=1)</sub> v[w<sub>i</sub>], get a vector from the query</li></ul>
							<li><strong>Mas_Similar</strong>(txt, model, topn):</li>
							<ul><li> Out: List of <strong>n items</strong> more closed in the Space model from vector(txt) </li></ul>
							<li><strong>Similares</strong>(term, jer='all', nMax=3):</li>
							<ul><li> Out: List of <strong>nMax</strong> more similar concepts from Snomed-CT, grouping by <strong>hierarchy </strong></li></ul>
						</ul>
						</small>
					</section>					
				</section>
					
				</section>
				
				
				<section>
					<section data-transition="zoom" data-background="images/cbms_fondo06.jpg">
						<h2 style="display:block;background:rgba(235,235,235,0.7);color:#404040;padding:13px 10px 10px 10px;border-radius:3px;">6. Use Cases:</h2>
					</section>	
				
					<section>
						<h2>Use case:</h2>
						<p><small><a href="http://snomed2vec.jasonjimnzdev.es/" target="_blank">Link to: On line Snomed2Vec protoype tool</a></small></p>
						<img src="images/EjemploSnomed2Vec01.png" style="border: 0; padding: 0px; width: 70%; height: 70%"> </img>
						<img src="images/EjemploSnomed2Vec03.png" style="border: 0; padding: 0px; width: 60%; height: 60%"> </img>
					</section>
					<section data-background-iframe="http://snomed2vec.jasonjimnzdev.es/" data-background-interactive>
						<div style="position: absolute; width: 20%; right: 0; box-shadow: 0 1px 4px rgba(0,0,0,0.5), 0 5px 25px rgba(0,0,0,0.2); background-color: rgba(0, 0, 0, 0.9); color: #fff; padding: 20px; font-size: 20px; text-align: left;">
							<h2>Snomed2Vec Tools Page</h2>
							<p>Prototype Snomed2Vec Web</p>
						</div>
					</section>
				</section>				
				<section>

					<section data-transition="zoom" data-background="images/cbms_fondo07.jpg">
						<h2 style="display:block;background:rgba(235,235,235,0.7);color:#404040;padding:13px 10px 10px 10px;border-radius:3px;">7. Evaluation and tips:</h2>
					</section>

					<section>
						<h2>Evaluations:</h2>
						<small>
						<p>We proposed, two kind of evaluations:<p>
						<ol>
							<li>Using a Corpus Gold Data, prepared for this experiment, with two Documentalist experts </li>
							<p>The performance of the tool: 
								Precision: P = TP/(TP+FP),
								Recall: R =TP/(TP+FN), where TP = true positive, TN=true negative, FN =False negative and FP= false positive.</p>
							<img src="images/F1_meassure.png" style="border: 0; padding: 0px; width: 60%; height: 60%"> </img>
							<img src="images/TableResults.png" style="border: 0; padding: 0px; width: 30%; height: 30%"> </img>
							<p>Use this survey:</p>
							<li><a href="https://docs.google.com/forms/d/e/1FAIpQLSerCEqABYqYXs69O1a8_JVuRd5B_dKmfpGRDw8BRWREm0P7lw/viewform">Link to: A social approach, to evaluate the paper, with a public survey.</a> </li>
						</ol>
					</small>
					</section>
					<section>
						<h2>Contributions:</h2>
						<p>We publish a Github repository, for this project, to share the Notebooks:<p>
						<p>Snomed2Vec Github: <a href="https://github.com/NachusS/Snomed2Vec">Link to: Snomed2Vec (https://github.com/NachusS/Snomed2Vec)</a></p>
						<p>You can reproduce and improve this development, with this code.</p>

					</section>					

				</section>					
				<section>				
					<section data-transition="zoom" data-background="images/cbms_fondo08.jpg">
						<h2 style="display:block;background:rgba(235,235,235,0.7);color:#404040;padding:13px 10px 10px 10px;border-radius:3px;">8. Conclusion and Outlook:</h2>
					</section>
					<section>
					<h2>Conclusions:</h2>
					<ol>
						<li>This is a tool, to help the human expert, choose the best SNOMED-CT Code.</li>
						<li>With a closed domain training model, the system can solve abbrevitions</li>
						<li>You can integrate with a N.E.R. system, and help to get the correct code. </li>
						<li>we offer publish notebooks to reproduce the project. And Test it. </li>
					</ol>
					</section>				
				</section>
				<section style="text-align: left;">
					<h1>THE END</h1>
					<p>
						Autores: <br>
						<img src="images/QR-EncuestaCBMS2019.png" style="float: right; border: 0; padding: 0px; width: 30%; height: 30%"></img>
						- <a href="https://nachuss.github.io/" target="_blank">Ignacio Martínez Soriano</a> <br>
						- <a href="http://decsai.ugr.es/index.php?p=profesores&id=7932" target="_blank">Juan Luis Castro Peña</a> <br>
						- <a href="https://webs.um.es/jfernand/miwiki/doku.php" target="_blank">Jesualdo Tomas Fenandez Breis</a> <br>
						- <a href="https://www.linkedin.com/in/ignaciosrl/?originalSubdomain=es" target="_blank">Ignacio San Roman Lana</a> <br>
						- <a href="https://medlabmediagroup.com/es/inicio/" target="_blank">Adrian Alonso</a> <br>
						- <a href="https://www.murciasalud.es/caps.php?op=mostrar_centro&id_centro=14&tipo_centro=hospital&idsec=6" target="_blank">David Guevara Baraza</a>
					</p>
					<hr>
					<p>
					<a target="_blank" href="https://docs.google.com/forms/d/e/1FAIpQLSdGoKAMT_jykJTzb2SnHiSXK-rTqSzm2HLG4Q0DdIzR0xbrhQ/viewform">Link to: Please fill Satisfaction Survey</a>
					
				</p>
				</section>

				

			</div>

		</div>

	<div style="position: absolute; bottom: 10px; left: 100%;  margin-left: -150px">
				<img src="images/logoSnomed.png">
	</div>			
		<script src="js/reveal.js"></script>
		<script src="lib/highlight.js"></script>

		<script>

			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				controlsLayout: 'edges',
				progress: true,
				slideNumber: true,
				center: true,
				hash: true,
				rollingLinks: true,
				transition: 'convex', // none/fade/slide/convex/concave/zoom

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true },
					{ src: 'plugin/search/search.js', async: true },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
